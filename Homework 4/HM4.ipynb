{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4: Build a CNN for Image Recognition\n",
    "\n",
    "### Name: Tyler Bryk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preparation\n",
    "\n",
    "### 1.1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x_train: (50000, 32, 32, 3)\n",
      "shape of y_train: (50000, 1)\n",
      "shape of x_test: (10000, 32, 32, 3)\n",
      "shape of y_test: (10000, 1)\n",
      "number of classes: 10\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "import numpy\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print('shape of x_train: ' + str(x_train.shape))\n",
    "print('shape of y_train: ' + str(y_train.shape))\n",
    "print('shape of x_test: ' + str(x_test.shape))\n",
    "print('shape of y_test: ' + str(y_test.shape))\n",
    "print('number of classes: ' + str(numpy.max(y_train) - numpy.min(y_train) + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. One-hot encode the labels\n",
    "\n",
    "In the input, a label is a scalar in $\\{0, 1, \\cdots , 9\\}$. One-hot encode transform such a scalar to a $10$-dim vector. E.g., a scalar ```y_train[j]=3``` is transformed to the vector ```y_train_vec[j]=[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]```.\n",
    "\n",
    "1. Define a function ```to_one_hot``` that transforms an $n\\times 1$ array to a $n\\times 10$ matrix.\n",
    "\n",
    "2. Apply the function to ```y_train``` and ```y_test```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y_train_vec: (50000, 10)\n",
      "Shape of y_test_vec: (10000, 10)\n",
      "[6]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "def to_one_hot(y, num_class=10):\n",
    "    results = numpy.zeros((len(y), num_class))\n",
    "    for i, label in enumerate(y):\n",
    "        results[i, label] = 1.\n",
    "    return results\n",
    "\n",
    "y_train_vec = to_one_hot(y_train)\n",
    "y_test_vec = to_one_hot(y_test)\n",
    "\n",
    "print('Shape of y_train_vec: ' + str(y_train_vec.shape))\n",
    "print('Shape of y_test_vec: ' + str(y_test_vec.shape))\n",
    "\n",
    "print(y_train[0])\n",
    "print(y_train_vec[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Image Data to Float-32\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# Standardize Data with Z-scores\n",
    "mean = numpy.mean(x_train, axis=(0,1,2,3))\n",
    "std  = numpy.std(x_train, axis=(0,1,2,3))\n",
    "x_train = (x_train - mean) / (std + 1e-7)\n",
    "x_test  = (x_test - mean) / (std + 1e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Randomly partition the training set to training and validation sets\n",
    "\n",
    "Randomly partition the 50K training samples to 2 sets:\n",
    "* a training set containing 40K samples\n",
    "* a validation set containing 10K samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_tr: (40000, 32, 32, 3)\n",
      "Shape of y_tr: (40000, 10)\n",
      "Shape of x_val: (10000, 32, 32, 3)\n",
      "Shape of y_val: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "rand_indices = numpy.random.permutation(50000)\n",
    "train_indices = rand_indices[0:40000]\n",
    "valid_indices = rand_indices[40000:50000]\n",
    "\n",
    "x_val = x_train[valid_indices, :]\n",
    "y_val = y_train_vec[valid_indices, :]\n",
    "\n",
    "x_tr = x_train[train_indices, :]\n",
    "y_tr = y_train_vec[train_indices, :]\n",
    "\n",
    "print('Shape of x_tr: ' + str(x_tr.shape))\n",
    "print('Shape of y_tr: ' + str(y_tr.shape))\n",
    "print('Shape of x_val: ' + str(x_val.shape))\n",
    "print('Shape of y_val: ' + str(y_val.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build a CNN and tune its hyper-parameters\n",
    "\n",
    "1. Build a convolutional neural network model\n",
    "2. Use the validation data to tune the hyper-parameters (e.g., network structure, and optimization algorithm)\n",
    "    * Do NOT use test data for hyper-parameter tuning!!!\n",
    "3. Try to achieve a validation accuracy as high as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,345,106\n",
      "Trainable params: 1,343,166\n",
      "Non-trainable params: 1,940\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.regularizers import l2\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=l2(1e-4), activation=\"relu\", input_shape=(32,32,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=l2(1e-4), activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=l2(1e-4), activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=l2(1e-4), activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=l2(1e-4), activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=l2(1e-4), activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(10))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "625/625 [==============================] - 43s 69ms/step - loss: 1.4541 - accuracy: 0.5121 - val_loss: 0.9724 - val_accuracy: 0.6383\n",
      "Epoch 2/40\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 1.1017 - accuracy: 0.6489 - val_loss: 0.8180 - val_accuracy: 0.7078\n",
      "Epoch 3/40\n",
      "625/625 [==============================] - 43s 69ms/step - loss: 0.9649 - accuracy: 0.6999 - val_loss: 1.0764 - val_accuracy: 0.7241\n",
      "Epoch 4/40\n",
      "625/625 [==============================] - 41s 66ms/step - loss: 0.8882 - accuracy: 0.7270 - val_loss: 0.7428 - val_accuracy: 0.7729\n",
      "Epoch 5/40\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 0.8387 - accuracy: 0.7444 - val_loss: 0.8329 - val_accuracy: 0.7653\n",
      "Epoch 6/40\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 0.8049 - accuracy: 0.7580 - val_loss: 0.8565 - val_accuracy: 0.7665\n",
      "Epoch 7/40\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 0.7808 - accuracy: 0.7675 - val_loss: 0.7876 - val_accuracy: 0.7876\n",
      "Epoch 8/40\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 0.7617 - accuracy: 0.7760 - val_loss: 0.7773 - val_accuracy: 0.8074\n",
      "Epoch 9/40\n",
      "625/625 [==============================] - 42s 66ms/step - loss: 0.7474 - accuracy: 0.7815 - val_loss: 0.8030 - val_accuracy: 0.8002\n",
      "Epoch 10/40\n",
      "625/625 [==============================] - 42s 66ms/step - loss: 0.7249 - accuracy: 0.7909 - val_loss: 0.5733 - val_accuracy: 0.8044\n",
      "Epoch 11/40\n",
      "625/625 [==============================] - 42s 66ms/step - loss: 0.7145 - accuracy: 0.7949 - val_loss: 0.4619 - val_accuracy: 0.8152\n",
      "Epoch 12/40\n",
      "625/625 [==============================] - 41s 66ms/step - loss: 0.7036 - accuracy: 0.7997 - val_loss: 0.4383 - val_accuracy: 0.8076\n",
      "Epoch 13/40\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 0.6994 - accuracy: 0.8030 - val_loss: 0.5725 - val_accuracy: 0.8365\n",
      "Epoch 14/40\n",
      "625/625 [==============================] - 42s 66ms/step - loss: 0.6889 - accuracy: 0.8055 - val_loss: 0.4632 - val_accuracy: 0.8008\n",
      "Epoch 15/40\n",
      "625/625 [==============================] - 41s 66ms/step - loss: 0.6746 - accuracy: 0.8124 - val_loss: 0.5892 - val_accuracy: 0.8456\n",
      "Epoch 16/40\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 0.6696 - accuracy: 0.8156 - val_loss: 0.5663 - val_accuracy: 0.8384\n",
      "Epoch 17/40\n",
      "625/625 [==============================] - 41s 66ms/step - loss: 0.6704 - accuracy: 0.8146 - val_loss: 0.4523 - val_accuracy: 0.8565\n",
      "Epoch 18/40\n",
      "625/625 [==============================] - 41s 66ms/step - loss: 0.6605 - accuracy: 0.8184 - val_loss: 0.6145 - val_accuracy: 0.8458\n",
      "Epoch 19/40\n",
      "625/625 [==============================] - 41s 66ms/step - loss: 0.6567 - accuracy: 0.8209 - val_loss: 0.6421 - val_accuracy: 0.8353\n",
      "Epoch 20/40\n",
      "625/625 [==============================] - 41s 66ms/step - loss: 0.6596 - accuracy: 0.8223 - val_loss: 0.3942 - val_accuracy: 0.8530\n",
      "Epoch 21/40\n",
      "625/625 [==============================] - 41s 66ms/step - loss: 0.6466 - accuracy: 0.8251 - val_loss: 0.6807 - val_accuracy: 0.8385\n",
      "Epoch 22/40\n",
      "625/625 [==============================] - 42s 66ms/step - loss: 0.6471 - accuracy: 0.8229 - val_loss: 0.5245 - val_accuracy: 0.8259\n",
      "Epoch 23/40\n",
      "625/625 [==============================] - 41s 66ms/step - loss: 0.6419 - accuracy: 0.8288 - val_loss: 0.8233 - val_accuracy: 0.8298\n",
      "Epoch 24/40\n",
      "625/625 [==============================] - 41s 66ms/step - loss: 0.6336 - accuracy: 0.8307 - val_loss: 0.4700 - val_accuracy: 0.8462\n",
      "Epoch 25/40\n",
      "625/625 [==============================] - 41s 66ms/step - loss: 0.6388 - accuracy: 0.8276 - val_loss: 0.5480 - val_accuracy: 0.8606\n",
      "Epoch 26/40\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 0.6337 - accuracy: 0.8329 - val_loss: 0.6637 - val_accuracy: 0.8364\n",
      "Epoch 27/40\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 0.6286 - accuracy: 0.8335 - val_loss: 0.5554 - val_accuracy: 0.8480\n",
      "Epoch 28/40\n",
      "625/625 [==============================] - 42s 66ms/step - loss: 0.6285 - accuracy: 0.8339 - val_loss: 0.5141 - val_accuracy: 0.8493\n",
      "Epoch 29/40\n",
      "625/625 [==============================] - 41s 66ms/step - loss: 0.6237 - accuracy: 0.8366 - val_loss: 0.8269 - val_accuracy: 0.8449\n",
      "Epoch 30/40\n",
      "625/625 [==============================] - 41s 66ms/step - loss: 0.6183 - accuracy: 0.8379 - val_loss: 0.6516 - val_accuracy: 0.8405\n",
      "Epoch 31/40\n",
      "625/625 [==============================] - 41s 66ms/step - loss: 0.6176 - accuracy: 0.8383 - val_loss: 0.5224 - val_accuracy: 0.8589\n",
      "Epoch 32/40\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 0.6138 - accuracy: 0.8399 - val_loss: 0.9207 - val_accuracy: 0.8479\n",
      "Epoch 33/40\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 0.6120 - accuracy: 0.8411 - val_loss: 0.4478 - val_accuracy: 0.8698\n",
      "Epoch 34/40\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 0.6134 - accuracy: 0.8412 - val_loss: 0.5255 - val_accuracy: 0.8681\n",
      "Epoch 35/40\n",
      "625/625 [==============================] - 41s 66ms/step - loss: 0.6062 - accuracy: 0.8421 - val_loss: 0.6383 - val_accuracy: 0.8624\n",
      "Epoch 36/40\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 0.6113 - accuracy: 0.8414 - val_loss: 0.4884 - val_accuracy: 0.8503\n",
      "Epoch 37/40\n",
      "625/625 [==============================] - 41s 66ms/step - loss: 0.6023 - accuracy: 0.8436 - val_loss: 0.5688 - val_accuracy: 0.8629\n",
      "Epoch 38/40\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 0.5996 - accuracy: 0.8451 - val_loss: 0.5783 - val_accuracy: 0.8639\n",
      "Epoch 39/40\n",
      "625/625 [==============================] - 41s 66ms/step - loss: 0.5999 - accuracy: 0.8450 - val_loss: 0.3326 - val_accuracy: 0.8593\n",
      "Epoch 40/40\n",
      "625/625 [==============================] - 41s 66ms/step - loss: 0.5995 - accuracy: 0.8464 - val_loss: 0.5971 - val_accuracy: 0.8702\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "gen = ImageDataGenerator(rotation_range=15, \n",
    "                         width_shift_range=0.1,  \n",
    "                         height_shift_range=0.1,\n",
    "                         shear_range=0.3,\n",
    "                         zoom_range=0.1, \n",
    "                         horizontal_flip=True)\n",
    "gen.fit(x_tr)\n",
    "train_generator = gen.flow(x_tr, y_tr, batch_size=64)\n",
    "test_generator = ImageDataGenerator().flow(x_val, y_val, batch_size=64)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=0.001, decay=1e-6),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit_generator(train_generator, steps_per_epoch=40000//64, epochs=40, validation_data=test_generator, validation_steps=10000//64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train (again) and evaluate the model\n",
    "\n",
    "- To this end, you have found the \"best\" hyper-parameters. \n",
    "- Now, fix the hyper-parameters and train the network on the entire training set (all the 50K training samples)\n",
    "- Evaluate your model on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Train the model on the entire training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "781/781 [==============================] - 52s 66ms/step - loss: 0.6239 - accuracy: 0.8400\n",
      "Epoch 2/40\n",
      "781/781 [==============================] - 50s 64ms/step - loss: 0.6187 - accuracy: 0.8405\n",
      "Epoch 3/40\n",
      "781/781 [==============================] - 50s 64ms/step - loss: 0.6162 - accuracy: 0.8402\n",
      "Epoch 4/40\n",
      "781/781 [==============================] - 50s 65ms/step - loss: 0.6115 - accuracy: 0.8442\n",
      "Epoch 5/40\n",
      "781/781 [==============================] - 51s 65ms/step - loss: 0.6103 - accuracy: 0.8436\n",
      "Epoch 6/40\n",
      "781/781 [==============================] - 51s 66ms/step - loss: 0.6114 - accuracy: 0.8461\n",
      "Epoch 7/40\n",
      "781/781 [==============================] - 49s 63ms/step - loss: 0.6091 - accuracy: 0.8450\n",
      "Epoch 8/40\n",
      "781/781 [==============================] - 50s 64ms/step - loss: 0.6091 - accuracy: 0.8459\n",
      "Epoch 9/40\n",
      "781/781 [==============================] - 50s 65ms/step - loss: 0.5970 - accuracy: 0.8490\n",
      "Epoch 10/40\n",
      "781/781 [==============================] - 50s 64ms/step - loss: 0.6001 - accuracy: 0.8487\n",
      "Epoch 11/40\n",
      "781/781 [==============================] - 50s 64ms/step - loss: 0.5925 - accuracy: 0.8507\n",
      "Epoch 12/40\n",
      "781/781 [==============================] - 50s 64ms/step - loss: 0.5953 - accuracy: 0.8490\n",
      "Epoch 13/40\n",
      "781/781 [==============================] - 50s 64ms/step - loss: 0.6024 - accuracy: 0.8488\n",
      "Epoch 14/40\n",
      "781/781 [==============================] - 50s 64ms/step - loss: 0.5903 - accuracy: 0.8526\n",
      "Epoch 16/40\n",
      "781/781 [==============================] - 50s 65ms/step - loss: 0.5881 - accuracy: 0.8502\n",
      "Epoch 17/40\n",
      "781/781 [==============================] - 50s 64ms/step - loss: 0.5884 - accuracy: 0.8532\n",
      "Epoch 18/40\n",
      "781/781 [==============================] - 50s 64ms/step - loss: 0.5894 - accuracy: 0.8510\n",
      "Epoch 19/40\n",
      "781/781 [==============================] - 50s 64ms/step - loss: 0.5878 - accuracy: 0.8525\n",
      "Epoch 20/40\n",
      "781/781 [==============================] - 50s 64ms/step - loss: 0.5820 - accuracy: 0.8562\n",
      "Epoch 21/40\n",
      "781/781 [==============================] - 50s 64ms/step - loss: 0.5816 - accuracy: 0.8553\n",
      "Epoch 22/40\n",
      "781/781 [==============================] - 49s 63ms/step - loss: 0.5809 - accuracy: 0.8536\n",
      "Epoch 23/40\n",
      "781/781 [==============================] - 50s 64ms/step - loss: 0.5758 - accuracy: 0.8572\n",
      "Epoch 24/40\n",
      "781/781 [==============================] - 51s 65ms/step - loss: 0.5781 - accuracy: 0.8570\n",
      "Epoch 25/40\n",
      "781/781 [==============================] - 51s 65ms/step - loss: 0.5774 - accuracy: 0.8577\n",
      "Epoch 26/40\n",
      "781/781 [==============================] - 50s 65ms/step - loss: 0.5763 - accuracy: 0.8565\n",
      "Epoch 27/40\n",
      "781/781 [==============================] - 52s 66ms/step - loss: 0.5779 - accuracy: 0.8545\n",
      "Epoch 28/40\n",
      "781/781 [==============================] - 51s 65ms/step - loss: 0.5732 - accuracy: 0.8571\n",
      "Epoch 29/40\n",
      "781/781 [==============================] - 51s 65ms/step - loss: 0.5716 - accuracy: 0.8584\n",
      "Epoch 30/40\n",
      "781/781 [==============================] - 51s 65ms/step - loss: 0.5717 - accuracy: 0.8595\n",
      "Epoch 31/40\n",
      "781/781 [==============================] - 52s 66ms/step - loss: 0.5751 - accuracy: 0.8562\n",
      "Epoch 32/40\n",
      "781/781 [==============================] - 50s 65ms/step - loss: 0.5688 - accuracy: 0.8597\n",
      "Epoch 33/40\n",
      "781/781 [==============================] - 50s 65ms/step - loss: 0.5725 - accuracy: 0.8584\n",
      "Epoch 34/40\n",
      "781/781 [==============================] - 50s 65ms/step - loss: 0.5654 - accuracy: 0.8603\n",
      "Epoch 35/40\n",
      "781/781 [==============================] - 50s 64ms/step - loss: 0.5666 - accuracy: 0.8605\n",
      "Epoch 36/40\n",
      "781/781 [==============================] - 50s 64ms/step - loss: 0.5637 - accuracy: 0.8594\n",
      "Epoch 37/40\n",
      "781/781 [==============================] - 50s 64ms/step - loss: 0.5649 - accuracy: 0.8613\n",
      "Epoch 38/40\n",
      "781/781 [==============================] - 50s 64ms/step - loss: 0.5677 - accuracy: 0.8599\n",
      "Epoch 39/40\n",
      "781/781 [==============================] - 51s 65ms/step - loss: 0.5699 - accuracy: 0.8599\n",
      "Epoch 40/40\n",
      "781/781 [==============================] - 50s 64ms/step - loss: 0.5618 - accuracy: 0.8635\n"
     ]
    }
   ],
   "source": [
    "gen = ImageDataGenerator(rotation_range=15, \n",
    "                         width_shift_range=0.1,  \n",
    "                         height_shift_range=0.1,\n",
    "                         shear_range=0.3,\n",
    "                         zoom_range=0.1, \n",
    "                         horizontal_flip=True)\n",
    "gen.fit(x_train)\n",
    "train_generator = gen.flow(x_train, y_train_vec, batch_size=64)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=0.001, decay=1e-6),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit_generator(train_generator, steps_per_epoch=50000//64, epochs=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Evaluate the model on the test set\n",
    "\n",
    "Do NOT used the test set until now. Make sure that your model parameters and hyper-parameters are independent of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s 337us/step\n",
      "loss = 0.5686637101173401\n",
      "accuracy = 0.8659999966621399\n"
     ]
    }
   ],
   "source": [
    "loss_and_acc = model.evaluate(x_test, y_test_vec)\n",
    "print('loss = ' + str(loss_and_acc[0]))\n",
    "print('accuracy = ' + str(loss_and_acc[1]))"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
