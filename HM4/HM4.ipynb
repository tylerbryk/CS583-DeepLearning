{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4: Build a CNN for Image Recognition\n",
    "\n",
    "### Name: Tyler Bryk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preparation\n",
    "\n",
    "### 1.1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x_train: (50000, 32, 32, 3)\n",
      "shape of y_train: (50000, 1)\n",
      "shape of x_test: (10000, 32, 32, 3)\n",
      "shape of y_test: (10000, 1)\n",
      "number of classes: 10\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "import numpy\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print('shape of x_train: ' + str(x_train.shape))\n",
    "print('shape of y_train: ' + str(y_train.shape))\n",
    "print('shape of x_test: ' + str(x_test.shape))\n",
    "print('shape of y_test: ' + str(y_test.shape))\n",
    "print('number of classes: ' + str(numpy.max(y_train) - numpy.min(y_train) + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. One-hot encode the labels\n",
    "\n",
    "In the input, a label is a scalar in $\\{0, 1, \\cdots , 9\\}$. One-hot encode transform such a scalar to a $10$-dim vector. E.g., a scalar ```y_train[j]=3``` is transformed to the vector ```y_train_vec[j]=[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]```.\n",
    "\n",
    "1. Define a function ```to_one_hot``` that transforms an $n\\times 1$ array to a $n\\times 10$ matrix.\n",
    "\n",
    "2. Apply the function to ```y_train``` and ```y_test```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y_train_vec: (50000, 10)\n",
      "Shape of y_test_vec: (10000, 10)\n",
      "[6]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "def to_one_hot(y, num_class=10):\n",
    "    results = numpy.zeros((len(y), num_class))\n",
    "    for i, label in enumerate(y):\n",
    "        results[i, label] = 1.\n",
    "    return results\n",
    "\n",
    "y_train_vec = to_one_hot(y_train)\n",
    "y_test_vec = to_one_hot(y_test)\n",
    "\n",
    "print('Shape of y_train_vec: ' + str(y_train_vec.shape))\n",
    "print('Shape of y_test_vec: ' + str(y_test_vec.shape))\n",
    "\n",
    "print(y_train[0])\n",
    "print(y_train_vec[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Image Data to Float-32\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# Standardize Data with Z-scores\n",
    "mean = numpy.mean(x_train, axis=(0,1,2,3))\n",
    "std  = numpy.std(x_train, axis=(0,1,2,3))\n",
    "x_train = (x_train - mean) / (std + 1e-7)\n",
    "x_test  = (x_test - mean) / (std + 1e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Randomly partition the training set to training and validation sets\n",
    "\n",
    "Randomly partition the 50K training samples to 2 sets:\n",
    "* a training set containing 40K samples\n",
    "* a validation set containing 10K samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_tr: (40000, 32, 32, 3)\n",
      "Shape of y_tr: (40000, 10)\n",
      "Shape of x_val: (10000, 32, 32, 3)\n",
      "Shape of y_val: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "rand_indices = numpy.random.permutation(50000)\n",
    "train_indices = rand_indices[0:40000]\n",
    "valid_indices = rand_indices[40000:50000]\n",
    "\n",
    "x_val = x_train[valid_indices, :]\n",
    "y_val = y_train_vec[valid_indices, :]\n",
    "\n",
    "x_tr = x_train[train_indices, :]\n",
    "y_tr = y_train_vec[train_indices, :]\n",
    "\n",
    "print('Shape of x_tr: ' + str(x_tr.shape))\n",
    "print('Shape of y_tr: ' + str(y_tr.shape))\n",
    "print('Shape of x_val: ' + str(x_val.shape))\n",
    "print('Shape of y_val: ' + str(y_val.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build a CNN and tune its hyper-parameters\n",
    "\n",
    "1. Build a convolutional neural network model\n",
    "2. Use the validation data to tune the hyper-parameters (e.g., network structure, and optimization algorithm)\n",
    "    * Do NOT use test data for hyper-parameter tuning!!!\n",
    "3. Try to achieve a validation accuracy as high as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,345,106\n",
      "Trainable params: 1,343,166\n",
      "Non-trainable params: 1,940\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.regularizers import l2\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=l2(1e-4), input_shape=(32,32,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=l2(1e-4)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=l2(1e-4)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=l2(1e-4)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=l2(1e-4)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=l2(1e-4)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "625/625 [==============================] - 43s 68ms/step - loss: 1.4372 - accuracy: 0.5164 - val_loss: 1.4614 - val_accuracy: 0.5772\n",
      "Epoch 2/40\n",
      "625/625 [==============================] - 41s 65ms/step - loss: 1.0944 - accuracy: 0.6488 - val_loss: 1.2678 - val_accuracy: 0.5674\n",
      "Epoch 3/40\n",
      "625/625 [==============================] - 41s 65ms/step - loss: 0.9581 - accuracy: 0.6962 - val_loss: 0.9060 - val_accuracy: 0.6994\n",
      "Epoch 4/40\n",
      "625/625 [==============================] - 40s 65ms/step - loss: 0.8839 - accuracy: 0.7228 - val_loss: 1.0449 - val_accuracy: 0.6823\n",
      "Epoch 5/40\n",
      "625/625 [==============================] - 41s 65ms/step - loss: 0.8266 - accuracy: 0.7462 - val_loss: 0.9078 - val_accuracy: 0.7466\n",
      "Epoch 6/40\n",
      "625/625 [==============================] - 41s 65ms/step - loss: 0.7884 - accuracy: 0.7578 - val_loss: 0.9497 - val_accuracy: 0.7676\n",
      "Epoch 7/40\n",
      "625/625 [==============================] - 41s 65ms/step - loss: 0.7523 - accuracy: 0.7732 - val_loss: 0.7326 - val_accuracy: 0.7644\n",
      "Epoch 8/40\n",
      "625/625 [==============================] - 41s 65ms/step - loss: 0.7233 - accuracy: 0.7847 - val_loss: 0.7343 - val_accuracy: 0.7785\n",
      "Epoch 9/40\n",
      "625/625 [==============================] - 41s 65ms/step - loss: 0.7115 - accuracy: 0.7891 - val_loss: 1.0327 - val_accuracy: 0.7623\n",
      "Epoch 10/40\n",
      "625/625 [==============================] - 41s 65ms/step - loss: 0.6973 - accuracy: 0.7937 - val_loss: 0.7087 - val_accuracy: 0.8130\n",
      "Epoch 11/40\n",
      "625/625 [==============================] - 41s 65ms/step - loss: 0.6740 - accuracy: 0.8032 - val_loss: 0.6632 - val_accuracy: 0.8112\n",
      "Epoch 12/40\n",
      "625/625 [==============================] - 41s 66ms/step - loss: 0.6592 - accuracy: 0.8083 - val_loss: 0.6135 - val_accuracy: 0.7917\n",
      "Epoch 13/40\n",
      "625/625 [==============================] - 41s 66ms/step - loss: 0.6466 - accuracy: 0.8134 - val_loss: 0.8134 - val_accuracy: 0.8101\n",
      "Epoch 14/40\n",
      "625/625 [==============================] - 41s 66ms/step - loss: 0.6358 - accuracy: 0.8205 - val_loss: 0.5840 - val_accuracy: 0.8378\n",
      "Epoch 15/40\n",
      "625/625 [==============================] - 41s 66ms/step - loss: 0.6240 - accuracy: 0.8250 - val_loss: 0.5340 - val_accuracy: 0.8243\n",
      "Epoch 16/40\n",
      "625/625 [==============================] - 41s 66ms/step - loss: 0.6174 - accuracy: 0.8264 - val_loss: 0.9923 - val_accuracy: 0.7798\n",
      "Epoch 17/40\n",
      "625/625 [==============================] - 41s 66ms/step - loss: 0.6060 - accuracy: 0.8324 - val_loss: 0.4769 - val_accuracy: 0.8444\n",
      "Epoch 18/40\n",
      "625/625 [==============================] - 41s 65ms/step - loss: 0.6038 - accuracy: 0.8318 - val_loss: 0.8564 - val_accuracy: 0.8276\n",
      "Epoch 19/40\n",
      "625/625 [==============================] - 41s 66ms/step - loss: 0.5955 - accuracy: 0.8372 - val_loss: 0.6603 - val_accuracy: 0.8456\n",
      "Epoch 20/40\n",
      "625/625 [==============================] - 41s 66ms/step - loss: 0.5919 - accuracy: 0.8374 - val_loss: 0.7355 - val_accuracy: 0.8473\n",
      "Epoch 21/40\n",
      "625/625 [==============================] - 41s 65ms/step - loss: 0.5826 - accuracy: 0.8443 - val_loss: 0.6478 - val_accuracy: 0.8209\n",
      "Epoch 22/40\n",
      "625/625 [==============================] - 41s 66ms/step - loss: 0.5865 - accuracy: 0.8423 - val_loss: 0.7423 - val_accuracy: 0.8111\n",
      "Epoch 23/40\n",
      "625/625 [==============================] - 41s 66ms/step - loss: 0.5738 - accuracy: 0.8447 - val_loss: 0.6960 - val_accuracy: 0.8399\n",
      "Epoch 24/40\n",
      "625/625 [==============================] - 41s 65ms/step - loss: 0.5717 - accuracy: 0.8474 - val_loss: 0.4210 - val_accuracy: 0.8439\n",
      "Epoch 25/40\n",
      "625/625 [==============================] - 41s 66ms/step - loss: 0.5611 - accuracy: 0.8522 - val_loss: 0.7268 - val_accuracy: 0.8254\n",
      "Epoch 26/40\n",
      "625/625 [==============================] - 43s 68ms/step - loss: 0.5564 - accuracy: 0.8551 - val_loss: 0.4403 - val_accuracy: 0.8518\n",
      "Epoch 27/40\n",
      "625/625 [==============================] - 41s 65ms/step - loss: 0.5546 - accuracy: 0.8547 - val_loss: 0.5143 - val_accuracy: 0.8390\n",
      "Epoch 28/40\n",
      "625/625 [==============================] - 41s 66ms/step - loss: 0.5529 - accuracy: 0.8557 - val_loss: 0.7895 - val_accuracy: 0.7939\n",
      "Epoch 29/40\n",
      "625/625 [==============================] - 41s 65ms/step - loss: 0.5428 - accuracy: 0.8624 - val_loss: 0.9085 - val_accuracy: 0.8081\n",
      "Epoch 30/40\n",
      "625/625 [==============================] - 41s 66ms/step - loss: 0.5445 - accuracy: 0.8607 - val_loss: 0.9303 - val_accuracy: 0.8009\n",
      "Epoch 31/40\n",
      "625/625 [==============================] - 41s 66ms/step - loss: 0.5389 - accuracy: 0.8636 - val_loss: 0.6756 - val_accuracy: 0.8514\n",
      "Epoch 32/40\n",
      "625/625 [==============================] - 41s 65ms/step - loss: 0.5332 - accuracy: 0.8660 - val_loss: 0.6596 - val_accuracy: 0.8506\n",
      "Epoch 33/40\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 0.5354 - accuracy: 0.8647 - val_loss: 0.6499 - val_accuracy: 0.8626\n",
      "Epoch 34/40\n",
      "625/625 [==============================] - 41s 66ms/step - loss: 0.5271 - accuracy: 0.8680 - val_loss: 0.5012 - val_accuracy: 0.8470\n",
      "Epoch 35/40\n",
      "625/625 [==============================] - 41s 66ms/step - loss: 0.5284 - accuracy: 0.8689 - val_loss: 0.8044 - val_accuracy: 0.8303\n",
      "Epoch 36/40\n",
      "625/625 [==============================] - 41s 66ms/step - loss: 0.5263 - accuracy: 0.8657 - val_loss: 0.5434 - val_accuracy: 0.8562\n",
      "Epoch 37/40\n",
      "625/625 [==============================] - 41s 66ms/step - loss: 0.5165 - accuracy: 0.8712 - val_loss: 0.3333 - val_accuracy: 0.8571\n",
      "Epoch 38/40\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 0.5182 - accuracy: 0.8705 - val_loss: 0.7374 - val_accuracy: 0.8447\n",
      "Epoch 39/40\n",
      "625/625 [==============================] - 41s 65ms/step - loss: 0.5179 - accuracy: 0.8693 - val_loss: 0.4899 - val_accuracy: 0.8415\n",
      "Epoch 40/40\n",
      "625/625 [==============================] - 41s 66ms/step - loss: 0.5146 - accuracy: 0.8715 - val_loss: 0.7460 - val_accuracy: 0.7869\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "gen = ImageDataGenerator(rotation_range=15, \n",
    "                         width_shift_range=0.1,  \n",
    "                         height_shift_range=0.1,\n",
    "                         shear_range=0.3,\n",
    "                         zoom_range=0.1, \n",
    "                         horizontal_flip=True)\n",
    "gen.fit(x_tr)\n",
    "train_generator = gen.flow(x_tr, y_tr, batch_size=64)\n",
    "test_generator = ImageDataGenerator().flow(x_val, y_val, batch_size=64)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=0.001, decay=1e-6),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit_generator(train_generator, steps_per_epoch=40000//64, epochs=40, validation_data=test_generator, validation_steps=10000//64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train (again) and evaluate the model\n",
    "\n",
    "- To this end, you have found the \"best\" hyper-parameters. \n",
    "- Now, fix the hyper-parameters and train the network on the entire training set (all the 50K training samples)\n",
    "- Evaluate your model on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Train the model on the entire training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "781/781 [==============================] - 50s 64ms/step - loss: 0.5427 - accuracy: 0.8636\n",
      "Epoch 2/40\n",
      "781/781 [==============================] - 48s 62ms/step - loss: 0.5398 - accuracy: 0.8660\n",
      "Epoch 3/40\n",
      "781/781 [==============================] - 48s 62ms/step - loss: 0.5307 - accuracy: 0.8705\n",
      "Epoch 4/40\n",
      "781/781 [==============================] - 48s 62ms/step - loss: 0.5304 - accuracy: 0.8688\n",
      "Epoch 5/40\n",
      "781/781 [==============================] - 48s 62ms/step - loss: 0.5257 - accuracy: 0.8711\n",
      "Epoch 6/40\n",
      "781/781 [==============================] - 48s 62ms/step - loss: 0.5237 - accuracy: 0.8723\n",
      "Epoch 7/40\n",
      "781/781 [==============================] - 48s 62ms/step - loss: 0.5182 - accuracy: 0.8744\n",
      "Epoch 8/40\n",
      "781/781 [==============================] - 48s 62ms/step - loss: 0.5202 - accuracy: 0.8734\n",
      "Epoch 9/40\n",
      "781/781 [==============================] - 48s 62ms/step - loss: 0.5148 - accuracy: 0.8768\n",
      "Epoch 10/40\n",
      "781/781 [==============================] - 48s 62ms/step - loss: 0.5113 - accuracy: 0.8746\n",
      "Epoch 11/40\n",
      "781/781 [==============================] - 48s 62ms/step - loss: 0.5139 - accuracy: 0.8755\n",
      "Epoch 12/40\n",
      "781/781 [==============================] - 48s 62ms/step - loss: 0.5090 - accuracy: 0.8770\n",
      "Epoch 13/40\n",
      "781/781 [==============================] - 49s 62ms/step - loss: 0.5053 - accuracy: 0.8781\n",
      "Epoch 14/40\n",
      "781/781 [==============================] - 48s 61ms/step - loss: 0.5030 - accuracy: 0.8791\n",
      "Epoch 15/40\n",
      "781/781 [==============================] - 48s 62ms/step - loss: 0.5033 - accuracy: 0.8793\n",
      "Epoch 16/40\n",
      "781/781 [==============================] - 48s 61ms/step - loss: 0.4951 - accuracy: 0.8823\n",
      "Epoch 17/40\n",
      "781/781 [==============================] - 48s 62ms/step - loss: 0.4998 - accuracy: 0.8808\n",
      "Epoch 18/40\n",
      "781/781 [==============================] - 48s 62ms/step - loss: 0.4981 - accuracy: 0.8808\n",
      "Epoch 19/40\n",
      "781/781 [==============================] - 48s 61ms/step - loss: 0.4932 - accuracy: 0.8819\n",
      "Epoch 20/40\n",
      "781/781 [==============================] - 48s 61ms/step - loss: 0.4919 - accuracy: 0.8841\n",
      "Epoch 21/40\n",
      "781/781 [==============================] - 48s 62ms/step - loss: 0.4946 - accuracy: 0.8831\n",
      "Epoch 22/40\n",
      "781/781 [==============================] - 48s 62ms/step - loss: 0.4894 - accuracy: 0.8853\n",
      "Epoch 23/40\n",
      "781/781 [==============================] - 48s 62ms/step - loss: 0.4914 - accuracy: 0.8823\n",
      "Epoch 24/40\n",
      "781/781 [==============================] - 49s 63ms/step - loss: 0.4889 - accuracy: 0.8849\n",
      "Epoch 25/40\n",
      "781/781 [==============================] - 49s 63ms/step - loss: 0.4861 - accuracy: 0.8865\n",
      "Epoch 26/40\n",
      "781/781 [==============================] - 50s 65ms/step - loss: 0.4828 - accuracy: 0.8880\n",
      "Epoch 27/40\n",
      "781/781 [==============================] - 50s 64ms/step - loss: 0.4832 - accuracy: 0.8882\n",
      "Epoch 28/40\n",
      "781/781 [==============================] - 50s 64ms/step - loss: 0.4850 - accuracy: 0.8883\n",
      "Epoch 29/40\n",
      "781/781 [==============================] - 50s 64ms/step - loss: 0.4846 - accuracy: 0.8866\n",
      "Epoch 30/40\n",
      "781/781 [==============================] - 50s 64ms/step - loss: 0.4802 - accuracy: 0.8864\n",
      "Epoch 31/40\n",
      "781/781 [==============================] - 49s 63ms/step - loss: 0.4797 - accuracy: 0.8888\n",
      "Epoch 32/40\n",
      "781/781 [==============================] - 49s 63ms/step - loss: 0.4762 - accuracy: 0.8892\n",
      "Epoch 33/40\n",
      "781/781 [==============================] - 49s 63ms/step - loss: 0.4774 - accuracy: 0.8888\n",
      "Epoch 34/40\n",
      "781/781 [==============================] - 49s 62ms/step - loss: 0.4815 - accuracy: 0.8888\n",
      "Epoch 35/40\n",
      "781/781 [==============================] - 49s 62ms/step - loss: 0.4749 - accuracy: 0.8891\n",
      "Epoch 36/40\n",
      "781/781 [==============================] - 49s 63ms/step - loss: 0.4715 - accuracy: 0.8911\n",
      "Epoch 37/40\n",
      "781/781 [==============================] - 49s 63ms/step - loss: 0.4723 - accuracy: 0.8914\n",
      "Epoch 38/40\n",
      "781/781 [==============================] - 49s 62ms/step - loss: 0.4759 - accuracy: 0.8886\n",
      "Epoch 39/40\n",
      "781/781 [==============================] - 49s 63ms/step - loss: 0.4718 - accuracy: 0.8919\n",
      "Epoch 40/40\n",
      "781/781 [==============================] - 49s 62ms/step - loss: 0.4684 - accuracy: 0.8912\n"
     ]
    }
   ],
   "source": [
    "gen = ImageDataGenerator(rotation_range=15, \n",
    "                         width_shift_range=0.1,  \n",
    "                         height_shift_range=0.1,\n",
    "                         shear_range=0.3,\n",
    "                         zoom_range=0.1, \n",
    "                         horizontal_flip=True)\n",
    "gen.fit(x_train)\n",
    "train_generator = gen.flow(x_train, y_train_vec, batch_size=64)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=0.001, decay=1e-6),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit_generator(train_generator, steps_per_epoch=50000//64, epochs=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Evaluate the model on the test set\n",
    "\n",
    "Do NOT used the test set until now. Make sure that your model parameters and hyper-parameters are independent of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 4s 363us/step\n",
      "loss = 0.5003511307239532\n",
      "accuracy = 0.8827000260353088\n"
     ]
    }
   ],
   "source": [
    "loss_and_acc = model.evaluate(x_test, y_test_vec)\n",
    "print('loss = ' + str(loss_and_acc[0]))\n",
    "print('accuracy = ' + str(loss_and_acc[1]))"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
